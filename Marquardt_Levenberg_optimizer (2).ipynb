{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "import time"
      ],
      "metadata": {
        "id": "vY8KP3BfBAcP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2yO1zw6F-7i8"
      },
      "outputs": [],
      "source": [
        "class MarquardtLevenberg(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3, lambd=1e-3):\n",
        "        defaults = dict(lr=lr, lambd=lambd)\n",
        "        super(MarquardtLevenberg, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            lambd = group['lambd']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('MarquardtLevenberg does not support sparse gradients')\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['prev_grad'] = torch.zeros_like(p.data)\n",
        "\n",
        "                prev_grad = state['prev_grad']\n",
        "                state['step'] += 1\n",
        "\n",
        "                # Marquardt-Levenberg update\n",
        "                A = grad.matmul(grad.t()) + lambd * torch.eye(grad.size(0), device=grad.device)\n",
        "                g = grad\n",
        "\n",
        "                # Measure time for matrix inversion\n",
        "                start_inv = time.time()\n",
        "                H_inv = torch.inverse(A)\n",
        "                end_inv = time.time()\n",
        "\n",
        "                # Measure time for matrix multiplication\n",
        "                start_mul = time.time()\n",
        "                delta = H_inv.matmul(g)\n",
        "                end_mul = time.time()\n",
        "\n",
        "                # Update parameter\n",
        "                p.data.add_(-lr * delta)\n",
        "\n",
        "                # Save timing information\n",
        "                if 'time_inv' not in state:\n",
        "                    state['time_inv'] = 0\n",
        "                    state['time_mul'] = 0\n",
        "                    state['time_other'] = 0\n",
        "\n",
        "                state['time_inv'] += (end_inv - start_inv)\n",
        "                state['time_mul'] += (end_mul - start_mul)\n",
        "                state['time_other'] += (end_inv - start_inv) + (end_mul - start_mul)\n",
        "\n",
        "                state['prev_grad'].copy_(grad)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def profile(self):\n",
        "        inv_time = 0\n",
        "        mul_time = 0\n",
        "        other_time = 0\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                if 'time_inv' in state:\n",
        "                    inv_time += state['time_inv']\n",
        "                    mul_time += state['time_mul']\n",
        "                    other_time += state['time_other']\n",
        "\n",
        "        total_time = inv_time + mul_time + other_time\n",
        "        print(f\"Matrix inversion time: {100 * inv_time / total_time:.2f}%\")\n",
        "        print(f\"Matrix multiplication time: {100 * mul_time / total_time:.2f}%\")\n",
        "        print(f\"Other operations time: {100 * other_time / total_time:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = torch.nn.Linear(10, 2)\n",
        "optimizer = MarquardtLevenberg(model.parameters(), lr=1e-3, lambd=1e-2)\n",
        "\n",
        "# data\n",
        "input = torch.randn(5, 10)\n",
        "target = torch.randn(5, 2)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    optimizer.step(closure)\n",
        "\n",
        "optimizer.profile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zCUOyd5DPkc",
        "outputId": "b85959f1-7715-444b-f153-9bb1504fdaf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix inversion time: 42.60%\n",
            "Matrix multiplication time: 7.40%\n",
            "Other operations time: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Zsl6qbPD3kQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}